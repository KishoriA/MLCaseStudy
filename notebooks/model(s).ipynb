{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting coremltools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/e0/22d3659411724228a7c96eb6d8f813cca0e9e9f8f0647b1163f1aa7965b2/coremltools-2.0-cp36-none-macosx_10_13_intel.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 6.4kB/s ta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.1.0 in /Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages (from coremltools) (3.6.1)\n",
      "Collecting six==1.10.0 (from coremltools)\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b44607ab535be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.10.0 in /Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages (from coremltools) (1.15.4)\n",
      "Requirement already satisfied: setuptools in /Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages (from protobuf>=3.1.0->coremltools) (39.0.1)\n",
      "\u001b[31mtensorflow-tensorboard 1.5.1 has requirement bleach==1.5.0, but you'll have bleach 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 1.5.1 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mdocker-compose 1.23.1 has requirement texttable<0.10,>=0.9.0, but you'll have texttable 1.5.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, coremltools\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "Successfully installed coremltools-2.0 six-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Keras version 2.2.4 detected. Last version known to be fully compatible of Keras is 2.1.6 .\n",
      "WARNING:root:TensorFlow version 1.12.0 detected. Last version known to be fully compatible is 1.5.0 .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>rest_bpress</th>\n",
       "      <th>blood_sugar</th>\n",
       "      <th>rest_electro</th>\n",
       "      <th>max_heart_rate</th>\n",
       "      <th>exercice_angina</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.0</td>\n",
       "      <td>asympt</td>\n",
       "      <td>140.0</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>135.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>atyp_angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>160.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>non_anginal</td>\n",
       "      <td>160.0</td>\n",
       "      <td>t</td>\n",
       "      <td>normal</td>\n",
       "      <td>160.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>asympt</td>\n",
       "      <td>140.0</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>135.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.0</td>\n",
       "      <td>asympt</td>\n",
       "      <td>140.0</td>\n",
       "      <td>t</td>\n",
       "      <td>left_vent_hyper</td>\n",
       "      <td>119.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age   chest_pain  rest_bpress blood_sugar     rest_electro  \\\n",
       "0  43.0       asympt        140.0           f           normal   \n",
       "1  39.0  atyp_angina        130.0           f           normal   \n",
       "2  39.0  non_anginal        160.0           t           normal   \n",
       "5  50.0       asympt        140.0           f           normal   \n",
       "6  59.0       asympt        140.0           t  left_vent_hyper   \n",
       "\n",
       "   max_heart_rate exercice_angina  disease  \n",
       "0           135.0             yes      1.0  \n",
       "1           160.0             yes      0.0  \n",
       "2           160.0              no      0.0  \n",
       "5           135.0              no      0.0  \n",
       "6           119.0             yes      1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data file\n",
    "data = pd.read_csv('../data/preprocessed.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of features available and remove one as that is the target feature and one is the unnamed column\n",
    "n_features = data.shape[1]-2\n",
    "\n",
    "# separate the features and the target/outcome\n",
    "x_feats = data.drop(['disease'], 1)\n",
    "y_feat = data['disease']\n",
    "y_feat = y_feat.astype('int64')\n",
    "# y_feat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre process the features\n",
    "# x-dataframe containing the training features\n",
    "\n",
    "\n",
    "def preprocess_features(x):\n",
    "    # new output dataframe\n",
    "    output = pd.DataFrame(index=x.index)\n",
    "    # iterate through each column in features\n",
    "    for col, col_data in x.iteritems():\n",
    "        # convert categorical data to dummy variables/ one hot encoding of the categorical variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)\n",
    "        output = output.join(col_data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the model and generats a report for the performance metrics\n",
    "\n",
    "\n",
    "def train(model, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    print(' ')\n",
    "    print(\"training dataset size\", len(x_train))\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc_train = model.score(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc_test = model.score(x_test, y_test)\n",
    "\n",
    "    print('time for training: ', end-start)\n",
    "    print('Accuracy of model on train dataset:  {:.2f} %'.format(\n",
    "        acc_train*100))\n",
    "    print('Accuracy of model on test dataset:  {:.2f} %'.format(acc_test*100))\n",
    "\n",
    "    print('CONFUSION MATRIX:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('RESULTS')\n",
    "    report = classification_report(y_pred, y_test)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for a new record coming in\n",
    "def predict_new_record(d, classifier):\n",
    "    if d['blood_sugar'] == 't':\n",
    "        d['blood_sugar'] = 1\n",
    "    else:\n",
    "        d['blood_sugar'] = 0\n",
    "\n",
    "    if d['exercice_angina'] == 'yes':\n",
    "        d['exercice_angina'] = 1\n",
    "    else:\n",
    "        d['exercice_angina'] = 0\n",
    "\n",
    "    temp = pd.DataFrame(columns=x_feats.columns)\n",
    "\n",
    "    for key, value in d.items():\n",
    "        if(type(value) == str):\n",
    "            col_name = str(key)+'_'+str(value)\n",
    "\n",
    "            temp.loc[0, col_name] = 1\n",
    "        else:\n",
    "            temp.loc[0, key] = value\n",
    "    temp.fillna(0, inplace=True)\n",
    "    temp = temp.astype('int64')\n",
    "    # print(temp.dtypes)\n",
    "    #classifier = pickle.load(open('model.sav', 'rb'))\n",
    "    result = classifier.predict(temp)\n",
    "    # print(result)\n",
    "    if result > 0.5:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted to one hot encodings for categorical variable\n",
    "x_feats = preprocess_features(x_feats)\n",
    "x_feats = x_feats.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  188\n",
      "no of positives in over sampled data: 94\n",
      "no of positives in over sampled data: 94\n"
     ]
    }
   ],
   "source": [
    "# SMOTE an algorith used for oversampling. It generates a dataset that has equal proportions of data samples for positive and negative classes\n",
    "# create new random samples from the minor class for equal distribution\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "# split data into training and testing datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_feats, y_feat, test_size=0.2, random_state=0)\n",
    "\n",
    "columns = x_train.columns\n",
    "os_data_x, os_data_y = os.fit_sample(x_train, y_train)\n",
    "os_data_x = pd.DataFrame(data=os_data_x, columns=columns)\n",
    "os_data_y = pd.DataFrame(data=os_data_y, columns=['disease'])\n",
    "os_data_x = os_data_x.astype('int64')\n",
    "os_data_y = os_data_y.astype('int64')\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \", len(os_data_x))\n",
    "\n",
    "print('no of positives in over sampled data:',\n",
    "      len(os_data_y[os_data_y['disease'] == 1]))\n",
    "print('no of positives in over sampled data:',\n",
    "      len(os_data_y[os_data_y['disease'] == 0]))\n",
    "\n",
    "x_train = os_data_x\n",
    "y_train = os_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------LOGISTIC REGRESSION----------------------\n",
      " \n",
      "training dataset size 188\n",
      "time for training:  0.0034270286560058594\n",
      "Accuracy of model on train dataset:  82.45 %\n",
      "Accuracy of model on test dataset:  73.17 %\n",
      "CONFUSION MATRIX:\n",
      "[[12  6]\n",
      " [ 5 18]]\n",
      "RESULTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69        17\n",
      "           1       0.78      0.75      0.77        24\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        41\n",
      "   macro avg       0.72      0.73      0.73        41\n",
      "weighted avg       0.73      0.73      0.73        41\n",
      "\n",
      "--------------SUPPORT VECTOR MACHINE----------------------\n",
      " \n",
      "training dataset size 188\n",
      "time for training:  0.013113021850585938\n",
      "Accuracy of model on train dataset:  51.60 %\n",
      "Accuracy of model on test dataset:  56.10 %\n",
      "CONFUSION MATRIX:\n",
      "[[ 1 17]\n",
      " [ 1 22]]\n",
      "RESULTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.50      0.10         2\n",
      "           1       0.96      0.56      0.71        39\n",
      "\n",
      "   micro avg       0.56      0.56      0.56        41\n",
      "   macro avg       0.51      0.53      0.40        41\n",
      "weighted avg       0.91      0.56      0.68        41\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------RANDOM FOREST CLASSIFIER----------------------\n",
      " \n",
      "training dataset size 188\n",
      "time for training:  0.032037973403930664\n",
      "Accuracy of model on train dataset:  99.47 %\n",
      "Accuracy of model on test dataset:  73.17 %\n",
      "CONFUSION MATRIX:\n",
      "[[14  4]\n",
      " [ 7 16]]\n",
      "RESULTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72        21\n",
      "           1       0.70      0.80      0.74        20\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        41\n",
      "   macro avg       0.74      0.73      0.73        41\n",
      "weighted avg       0.74      0.73      0.73        41\n",
      "\n",
      "--------------DECISION TREE CLASSIFIER----------------------\n",
      " \n",
      "training dataset size 188\n",
      "time for training:  0.0031061172485351562\n",
      "Accuracy of model on train dataset:  100.00 %\n",
      "Accuracy of model on test dataset:  68.29 %\n",
      "CONFUSION MATRIX:\n",
      "[[13  5]\n",
      " [ 8 15]]\n",
      "RESULTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67        21\n",
      "           1       0.65      0.75      0.70        20\n",
      "\n",
      "   micro avg       0.68      0.68      0.68        41\n",
      "   macro avg       0.69      0.68      0.68        41\n",
      "weighted avg       0.69      0.68      0.68        41\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/dgeek/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# define models\n",
    "print('--------------LOGISTIC REGRESSION----------------------')\n",
    "classifier_lr = LogisticRegression(multi_class='ovr')\n",
    "train(classifier_lr, x_train, y_train, x_test, y_test)\n",
    "coreml_model = coremltools.converters.sklearn.convert(\n",
    "    classifier_lr, input_features=list(x_train.columns), output_feature_names='disease')\n",
    "coreml_model.save('model_lr.mlmodel')\n",
    "\n",
    "print('--------------SUPPORT VECTOR MACHINE----------------------')\n",
    "classifier_svc = LinearSVC()\n",
    "train(classifier_svc, x_train, y_train, x_test, y_test)\n",
    "coreml_model = coremltools.converters.sklearn.convert(\n",
    "    classifier_svc, input_features=list(x_train.columns), output_feature_names='disease')\n",
    "coreml_model.save('model_svc.mlmodel')\n",
    "\n",
    "print('--------------RANDOM FOREST CLASSIFIER----------------------')\n",
    "classifier_rf = RandomForestClassifier()\n",
    "train(classifier_rf, x_train, y_train, x_test, y_test)\n",
    "coreml_model = coremltools.converters.sklearn.convert(\n",
    "    classifier_rf, input_features=list(x_train.columns), output_feature_names='disease')\n",
    "coreml_model.save('model_randomforest.mlmodel')\n",
    "\n",
    "print('--------------DECISION TREE CLASSIFIER----------------------')\n",
    "classifier_dc = DecisionTreeClassifier()\n",
    "train(classifier_dc, x_train, y_train, x_test, y_test)\n",
    "coreml_model = coremltools.converters.sklearn.convert(\n",
    "    classifier_dc, input_features=list(x_train.columns), output_feature_names='disease')\n",
    "coreml_model.save('model_decisiontree.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 16 features per sample; expecting 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-263eb7c200e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m      'rest_electro': 'normal', 'max_heart_rate': 120, 'exercice_angina': 'no'}\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_new_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_new_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_svc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-768979776b51>\u001b[0m in \u001b[0;36mpredict_new_record\u001b[0;34m(d, classifier)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#print(temp.dtypes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#classifier = pickle.load(open('model.sav', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m#print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/dl/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 16 features per sample; expecting 14"
     ]
    }
   ],
   "source": [
    "# accept new record and predict\n",
    "d = {'age': 43, 'chest_pain': 'asympt', 'rest_bpress': 140, 'blood_sugar': 'f',\n",
    "     'rest_electro': 'normal', 'max_heart_rate': 120, 'exercice_angina': 'no'}\n",
    "print('Logistic Regression')\n",
    "print(predict_new_record(d, classifier_lr))\n",
    "print('SVM')\n",
    "print(predict_new_record(d, classifier_svc))\n",
    "print('Random Forest')\n",
    "print(predict_new_record(d, classifier_rf))\n",
    "print('Decision Tree')\n",
    "print(predict_new_record(d, classifier_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
